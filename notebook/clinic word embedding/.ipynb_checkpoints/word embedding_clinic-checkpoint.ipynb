{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65d3a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "import joblib\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b570f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset = ir_datasets.load(\"clinicaltrials/2021/trec-ct-2021\")\n",
    "\n",
    "# Create a corpus from the dataset\n",
    "corpus = {}\n",
    "\n",
    "\n",
    "for doc in dataset.docs_iter():\n",
    "        corpus[doc.doc_id]= doc.title+\" \" + doc.summary+\" \" +doc.detailed_description+ \" \"+doc.eligibility\n",
    "\n",
    "\n",
    "        \n",
    "documents = list(corpus.values())\n",
    "\n",
    "def custom_tokenizer(text: str) -> List[str]:\n",
    "    \"\"\"Tokenizes and lowercases the text.\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return tokens\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"Converts POS tag to a format that WordNetLemmatizer can understand.\"\"\"\n",
    "    tag = tag[0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def remove_markers(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"Removes specific markers from tokens.\"\"\"\n",
    "    return [re.sub(r'\\u00AE', '', token) for token in tokens]\n",
    "\n",
    "def remove_punctuation(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"Removes punctuation from tokens.\"\"\"\n",
    "    return [token.translate(str.maketrans('', '', string.punctuation)) for token in tokens]\n",
    "\n",
    "def replace_under_score_with_space(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"Replaces underscores with spaces in tokens.\"\"\"\n",
    "    return [re.sub(r'_', ' ', token) for token in tokens]\n",
    "\n",
    "def remove_apostrophe(tokens: List[str]) -> List[str]:\n",
    "    \"\"\"Removes apostrophes from tokens.\"\"\"\n",
    "    return [token.replace(\"'\", \" \") for token in tokens]\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Preprocesses the input text by tokenizing, removing punctuation, stopwords, and then stemming and lemmatizing.\"\"\"\n",
    "    # Convert text to lowercase and tokenize\n",
    "    words = custom_tokenizer(text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    words = [word.translate(str.maketrans('', '', string.punctuation)) for word in words]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "  \n",
    "    # Further token cleaning\n",
    "    words = remove_markers(words)\n",
    "    words = replace_under_score_with_space(words)\n",
    "    words = remove_apostrophe(words)\n",
    "    \n",
    "    # Stemming and Lemmatization\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    \n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "177930e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess documents\n",
    "processed_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(processed_documents, vector_size=100, sg=1, epochs=35)\n",
    "# Save the Word2Vec model\n",
    "word2vec_model.save(\"word2vec_model.kv\")\n",
    "# Load the Word2Vec model\n",
    "\n",
    "word2vec_model = Word2Vec.load(\"word2vec_model.kv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28290fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 100)\n",
      "[[-0.10790251  0.07500684 -0.01604374 -0.01004464  0.03876299 -0.09808514\n",
      "   0.11913601  0.2380268  -0.19215897 -0.16575484  0.08744249 -0.14581177\n",
      "  -0.02413175  0.00060287  0.07059655 -0.05456073  0.08935386  0.13905866\n",
      "  -0.10802566 -0.22537753 -0.01153983 -0.04480154  0.2252714   0.04268706\n",
      "   0.00588301  0.00027551  0.04724631  0.03625733 -0.06456638  0.00804974\n",
      "   0.1042631  -0.09287074  0.08524069 -0.02921432 -0.01848078  0.07960512\n",
      "   0.10697426  0.02149033 -0.01022009 -0.00835758  0.05861205 -0.08693418\n",
      "  -0.12006839  0.17266528  0.09777568  0.04610687 -0.06807119 -0.02557588\n",
      "   0.0351688  -0.00535286  0.01504784 -0.09418752 -0.05876078 -0.07933404\n",
      "  -0.09656384 -0.05836874  0.05929447 -0.10526424  0.04584054  0.02066694\n",
      "   0.00090336 -0.0163998   0.25067776 -0.04668289 -0.13967212  0.15689991\n",
      "   0.00059547  0.18528076 -0.12016471  0.00125129  0.07839196  0.14561716\n",
      "   0.12560524  0.1881562   0.07989281  0.13964246  0.11088531  0.06289683\n",
      "  -0.06878491 -0.09257822 -0.07388183 -0.08490862  0.02895815  0.05674087\n",
      "  -0.05772324 -0.08765712  0.10422096 -0.08876499  0.04068548 -0.03658055\n",
      "   0.06987287  0.11446819  0.09398843  0.02954374  0.24179392  0.06123521\n",
      "   0.19898713 -0.13641676  0.11327924 -0.06218127]\n",
      " [-0.10547021  0.07684936 -0.01466291 -0.00958456  0.03993542 -0.09760324\n",
      "   0.11800958  0.2394571  -0.19261776 -0.16484857  0.08496802 -0.14596665\n",
      "  -0.02259115  0.00287384  0.07054232 -0.05468668  0.09304617  0.13986833\n",
      "  -0.10652636 -0.22760811 -0.01168973 -0.04601676  0.22356169  0.03898276\n",
      "   0.00362953  0.00187442  0.04323447  0.03853628 -0.06277057  0.0093221\n",
      "   0.10655412 -0.09306511  0.08114442 -0.03156009 -0.01989592  0.07910676\n",
      "   0.10753295  0.02043565 -0.01270957 -0.0082891   0.06058636 -0.08808236\n",
      "  -0.11803804  0.17187485  0.09704275  0.04478887 -0.06768922 -0.0297838\n",
      "   0.03380061 -0.00662986  0.01722114 -0.09590366 -0.05933706 -0.07879821\n",
      "  -0.0983955  -0.05818744  0.05867715 -0.10445951  0.04533749  0.01914405\n",
      "  -0.00058752 -0.01951758  0.25096768 -0.04320129 -0.13884228  0.15999731\n",
      "   0.00353431  0.18367721 -0.12279295  0.00377034  0.07539033  0.14583468\n",
      "   0.12531985  0.18676452  0.08078295  0.13837853  0.11075609  0.06563851\n",
      "  -0.06860976 -0.09084734 -0.07664368 -0.08381471  0.02837781  0.05771658\n",
      "  -0.05754155 -0.08861659  0.10455028 -0.08838796  0.04118429 -0.03533705\n",
      "   0.07048153  0.11156504  0.09366968  0.02623249  0.24047022  0.05953975\n",
      "   0.20057511 -0.13272204  0.11292782 -0.0585776 ]\n",
      " [-0.10395994  0.08393691 -0.00923299 -0.01179501  0.03915675 -0.09584129\n",
      "   0.1139692   0.24277891 -0.19097936 -0.15932423  0.07970861 -0.14488487\n",
      "  -0.01783596  0.00363272  0.06938518 -0.06096587  0.09751421  0.13678943\n",
      "  -0.10608381 -0.23011704 -0.01308535 -0.046416    0.22053495  0.03479404\n",
      "  -0.00637299  0.00238206  0.03872895  0.04385081 -0.0615502   0.01140973\n",
      "   0.10572866 -0.09748726  0.07011155 -0.03897982 -0.02133392  0.07936417\n",
      "   0.11296267  0.01746226 -0.02046769 -0.00576078  0.0617761  -0.08755534\n",
      "  -0.11840243  0.16748674  0.09477083  0.03610367 -0.06688396 -0.03484465\n",
      "   0.0281645  -0.00850287  0.02168821 -0.09599519 -0.0578651  -0.07825525\n",
      "  -0.10135148 -0.05862017  0.05975511 -0.10338367  0.0415206   0.01558784\n",
      "  -0.00338774 -0.02862334  0.24851954 -0.03988431 -0.13542676  0.16214219\n",
      "   0.01028847  0.18183509 -0.1278975   0.00723612  0.07126521  0.14817758\n",
      "   0.12216014  0.18137996  0.08143224  0.13999021  0.10994993  0.07016232\n",
      "  -0.07008139 -0.08534948 -0.08127111 -0.0775518   0.03140728  0.06043156\n",
      "  -0.0626509  -0.08843622  0.10344268 -0.08309399  0.04196258 -0.02670946\n",
      "   0.07139505  0.10534364  0.09291913  0.01304344  0.24100651  0.06017938\n",
      "   0.20263082 -0.12575422  0.11237781 -0.05469441]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vectorize_documents(documents: List[List[str]]) -> np.ndarray:\n",
    "    documents_vectors = []\n",
    "    for document in documents:\n",
    "        zero_vector = np.zeros(200)\n",
    "        vectors = []\n",
    "        for token in document:\n",
    "            if token in word2vec_model.wv:\n",
    "                vectors.append(word2vec_model.wv[token])\n",
    "        if vectors:\n",
    "            vectors = np.asarray(vectors)\n",
    "            avg_vec = vectors.mean(axis=0)\n",
    "            documents_vectors.append(avg_vec)\n",
    "        else:\n",
    "            documents_vectors.append(zero_vector)\n",
    "    return np.array(documents_vectors)\n",
    "\n",
    "\n",
    "\n",
    "# Compute document vectors\n",
    "doc_vectors = vectorize_documents(processed_documents)\n",
    "print(doc_vectors.shape)\n",
    "print(doc_vectors)\n",
    "\n",
    "\n",
    "# Save and load functions for TF-IDF data\n",
    "def save_file(file_location: str, content):\n",
    "    with open(file_location, 'wb') as file:\n",
    "        pickle.dump(content, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_file(file_location: str):\n",
    "    with open(file_location, 'rb') as file:\n",
    "        loaded_file = pickle.load(file)\n",
    "    return loaded_file\n",
    "save_file(\"doc_vectors.pkl\",doc_vectors)\n",
    "doc_vectors = load_file(\"doc_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "991f822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector(query: str, model) -> np.ndarray:\n",
    "    tokens = custom_tokenizer(preprocess_text(query))\n",
    "\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vectors.append(model.wv[token])\n",
    "    if vectors:\n",
    "        vectors = np.asarray(vectors)\n",
    "        avg_vec = vectors.mean(axis=0)\n",
    "        return avg_vec\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "\n",
    "def compute_relevance_scores(query_text: str) -> List[str]:\n",
    "    \"\"\"Compute relevance scores between a query vector and all document vectors.\"\"\"\n",
    "    query_vec = query_vector(query_text, word2vec_model).reshape(1, -1)\n",
    "    similarities = cosine_similarity(doc_vectors, query_vec).flatten()\n",
    "    top_10_indices = similarities.argsort()[-10:][::-1]\n",
    "    return [list(corpus.keys())[index] for index in top_10_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dd4b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall_at_k(relevant_docs, retrieved_docs, k):\n",
    "    y_true = [1 if doc_id in relevant_docs else 0 for doc_id in retrieved_docs[:k]]\n",
    "    true_positives = sum([1 for i in range(len(y_true)) if y_true[i] == 1])\n",
    "    recall_at_k = true_positives / len(relevant_docs)\n",
    "    precision_at_k = true_positives / k\n",
    "    print(f\"Recall@{k}: {recall_at_k}\")\n",
    "    print(f\"Precision@{k}: {precision_at_k}\")\n",
    "    return precision_at_k, recall_at_k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5092803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n",
      "Recall@10: 0.0\n",
      "Precision@10: 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_recall_precision(query_id):\n",
    "    relevant_docs = []\n",
    "    retrieved_docs = []\n",
    "    \n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == query_id:\n",
    "            if qrel.relevance > 0:\n",
    "                relevant_docs.append(qrel.doc_id)\n",
    "\n",
    "    for query in dataset.queries_iter():\n",
    "        if query.query_id == query_id:\n",
    "            retrieved_docs = compute_relevance_scores(query.text)\n",
    "            break\n",
    "    \n",
    "    truncated_retrieved_docs = retrieved_docs[:len(relevant_docs)]\n",
    "    compute_precision_recall_at_k(relevant_docs, retrieved_docs, 10)\n",
    "\n",
    "# Evaluate queries\n",
    "queries_ids = {}\n",
    "for qrel in dataset.qrels_iter():\n",
    "    queries_ids.update({qrel.query_id: ''})\n",
    "\n",
    "for query_id in list(queries_ids.keys()):\n",
    "    calculate_recall_precision(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bf90bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision : 0.0\n"
     ]
    }
   ],
   "source": [
    "def calculate_MAP(query_id):\n",
    "    relevant_docs = []\n",
    "    retrieved_docs = []\n",
    "\n",
    "    # Get relevant documents for the query\n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == query_id and qrel.relevance > 0:\n",
    "            relevant_docs.append(qrel.doc_id)\n",
    "\n",
    "    # Get retrieved documents for the query\n",
    "    for query in dataset.queries_iter():\n",
    "        if query.query_id == query_id:\n",
    "            retrieved_docs = compute_relevance_scores(query.text)\n",
    "            break\n",
    "\n",
    "    # Compute mean average precision\n",
    "    pk_sum = 0\n",
    "    total_relevant = 0\n",
    "    for i in range(1, 11):\n",
    "        relevant_ret = 0\n",
    "        for j in range(i):\n",
    "            if j < len(retrieved_docs) and retrieved_docs[j] in relevant_docs:\n",
    "                relevant_ret += 1\n",
    "        p_at_k = (relevant_ret / i) * (1 if i - 1 < len(retrieved_docs) and retrieved_docs[i - 1] in relevant_docs else 0)\n",
    "        pk_sum += p_at_k\n",
    "        if i - 1 < len(retrieved_docs) and retrieved_docs[i - 1] in relevant_docs:\n",
    "            total_relevant += 1\n",
    "\n",
    "    return 0 if total_relevant == 0 else pk_sum / total_relevant\n",
    "\n",
    "queries_ids = {qrel[0]: '' for qrel in dataset.qrels_iter()}\n",
    "\n",
    "map_sum = 0\n",
    "for query_id in list(queries_ids.keys()):\n",
    "    map_sum += calculate_MAP(query_id)\n",
    "\n",
    "print(f\"Mean Average Precision : {map_sum / len(queries_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84e28e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank : 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_MRR(query_id):\n",
    "    relevant_docs = []\n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == query_id and qrel.relevance > 0:\n",
    "            relevant_docs.append(qrel.doc_id)\n",
    "    \n",
    "    retrieved_docs = []\n",
    "    for query in dataset.queries_iter():\n",
    "        if query.query_id == query_id:\n",
    "            retrieved_docs = compute_relevance_scores(query.text)\n",
    "            break\n",
    "\n",
    "    for i, result in enumerate(retrieved_docs):\n",
    "        if result in relevant_docs:\n",
    "            return 1 / (i + 1)\n",
    "\n",
    "    return 0\n",
    "\n",
    "queries_ids = {}\n",
    "for qrel in dataset.qrels_iter():\n",
    "    queries_ids.update({qrel.query_id: ''})\n",
    "\n",
    "mrr_sum = 0\n",
    "for query_id in list(queries_ids.keys()):\n",
    "    mrr_sum += calculate_MRR(query_id)\n",
    "\n",
    "print(f\"Mean Reciprocal Rank : {mrr_sum / len(queries_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f634f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
